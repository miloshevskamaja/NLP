# -*- coding: utf-8 -*-
"""lab2-2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_4zMZWpP_WSuCWVPDganUg2LIq8bOW55
"""

import torch

if torch.cuda.is_available():
  torch.cuda.manual_seed(42)
  device = torch.device("cuda")
  print("Ok")
else:
  print("Not ok")

import pandas as pd

data = pd.read_csv('train_en.txt', sep='\t')

positive_data = data[data['Style']== 'positive'].sample(n=5000, random_state=42)
negative_data = data[data['Style'] == 'negative'].sample(n=5000, random_state=42)

balanced_data = pd.concat([positive_data, negative_data], ignore_index=True)
balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)

balanced_data['Label'] = [1 if label == 'positive' else 0 for label in balanced_data['Style']]

train_texts = balanced_data['Sentence'].tolist()
train_labels = balanced_data['Label'].tolist()

test_data = pd.read_csv('test_en.txt', sep='\t')
test_data['Label'] = [1 if label == 'positive' else 0 for label in test_data['Style']]

test_texts = test_data['Sentence'].tolist()
test_labels = test_data['Label'].tolist()

"""PART 1

RoBERTa
"""

from transformers import (AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer)

tokenizer_ro = AutoTokenizer.from_pretrained('roberta-base')

train_encodings_ro = tokenizer_ro(train_texts, truncation=True, padding=True, max_length=512)

test_encodings_ro = tokenizer_ro(test_texts, truncation=True, padding=True, max_length=512)

model_ro = AutoModelForSequenceClassification.from_pretrained('roberta-base', num_labels=2)

model_ro = model_ro.to(device)

from torch.utils.data import Dataset

class SentimentDataset(Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)

train_ds_ro = SentimentDataset(train_encodings_ro, train_labels)

test_ds_ro = SentimentDataset(test_encodings_ro, test_labels)

training_args = TrainingArguments(output_dir='roberta_sentiment', report_to='none', learning_rate=2e-5,
                                  num_train_epochs=3, weight_decay=0.005)

trainer_ro = Trainer (model=model_ro, args = training_args, train_dataset=train_ds_ro, tokenizer=tokenizer_ro)

trainer_ro.train()

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import numpy as np

pred_ro = trainer_ro.predict(test_ds_ro)

y_pred_ro = np.argmax(pred_ro.predictions, axis=1)
y_true = test_labels

accuracy_ro = accuracy_score(y_true, y_pred_ro)
recall_ro = recall_score(y_true, y_pred_ro)
precision_ro = precision_score(y_true, y_pred_ro)
f1_ro = f1_score(y_true, y_pred_ro)

print(f"Accuracy: {accuracy_ro:.2f}")
print(f"Recall: {recall_ro:.2f}")
print(f"Precision: {precision_ro:.2f}")
print(f"F1-score: {f1_ro:.2f}")



"""DistilBERT"""

tokenizer_db = AutoTokenizer.from_pretrained('distilbert-base-uncased')

train_encodings_db = tokenizer_db(train_texts, padding=True, truncation=True, max_length=512)
test_encodings_db = tokenizer_db(test_texts, padding=True, truncation=True, max_length=512)

model_db = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)
model_db = model_db.to(device)

train_ds_db = SentimentDataset(train_encodings_db, train_labels)
test_ds_db = SentimentDataset(test_encodings_db, test_labels)

training_args_db = TrainingArguments(output_dir='distilbert_sentiment', report_to='none', learning_rate=2e-5,
                                  num_train_epochs=3, weight_decay=0.01)

trainer_db = Trainer (model=model_db, args = training_args_db, train_dataset=train_ds_db, tokenizer=tokenizer_db )

trainer_db.train()

pred_db = trainer_db.predict(test_ds_db)

y_pred_db = np.argmax(pred_db.predictions, axis=1)
y_true = test_labels

accuracy_db = accuracy_score(y_true, y_pred_db)
recall_db = recall_score(y_true, y_pred_db)
precision_db = precision_score(y_true, y_pred_db)
f1_db = f1_score(y_true, y_pred_db)

print(f"Accuracy: {accuracy_db:.2f}")
print(f"Recall: {recall_db:.2f}")
print(f"Precision: {precision_db:.2f}")
print(f"F1-score: {f1_db:.2f}")

"""* Овие модели даваат подобри резултати од претходната лабораториска вежба, што е очекувано бидејќи трансформер архитектурите се многу подобри од традиционалните модели поради тоа што се претренирани на огромни обем на податоци
 * RoBERTa дава малку подобри од DistilBERT бидејќи е поголем модел

PART 2

T5 zero-shot & few-shot prompting
"""

from transformers import T5Tokenizer, T5ForConditionalGeneration

tokenizer_t5 = T5Tokenizer.from_pretrained("t5-small")

model_t5 = T5ForConditionalGeneration.from_pretrained("t5-small")

def zero_shot_t5(sentence):
  prompt = f"Classify the sentiment as positive or negative:\n{sentence}"

  input_ids = tokenizer_t5(prompt, return_tensors="pt").input_ids

  output_ids = model_t5.generate(input_ids, max_length=5)
  prediction = tokenizer_t5.decode(output_ids[0], skip_special_tokens=True).lower()

  if "positive" in prediction:
        return "positive"
  elif "negative" in prediction:
        return "negative"
  else:
        return "negative"

def few_shot_t5(sentence):
  prompt = f"""
Review: I love this place.
Sentiment: positive

Review: The service was terrible.
Sentiment: negative

Now classify:
Review: {sentence}
Sentiment:
"""
  input_ids = tokenizer_t5(prompt, return_tensors="pt").input_ids
  output_ids = model_t5.generate(input_ids, max_length=5)

  prediction = tokenizer_t5.decode(output_ids[0], skip_special_tokens=True).lower().strip()
  if "positive" in prediction:
        return "positive"
  elif "negative" in prediction:
        return "negative"
  else:
        return "negative"

balanced_data["t5_zero_shot"] = balanced_data["Sentence"].apply(zero_shot_t5)

balanced_data["t5_few_shot"] = balanced_data["Sentence"].apply(few_shot_t5)



balanced_data["t5_few_shot"].value_counts()

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

print("ZERO SHOT T5 RESULTS:")
print("Accuracy:", accuracy_score(balanced_data["Style"], balanced_data["t5_zero_shot"]))
print("Precision:", precision_score(balanced_data["Style"], balanced_data["t5_zero_shot"], pos_label="positive", zero_division=0))
print("Recall:", recall_score(balanced_data["Style"], balanced_data["t5_zero_shot"], pos_label="positive", zero_division=0))
print("F1:", f1_score(balanced_data["Style"], balanced_data["t5_zero_shot"], pos_label="positive", zero_division=0))

print("FEW SHOT:")
print(accuracy_score(balanced_data["Style"], balanced_data["t5_few_shot"]))
print(precision_score(balanced_data["Style"], balanced_data["t5_few_shot"], pos_label="positive", zero_division=0))
print(recall_score(balanced_data["Style"], balanced_data["t5_few_shot"], pos_label="positive", zero_division=0))
print(f1_score(balanced_data["Style"], balanced_data["t5_few_shot"], pos_label="positive", zero_division=0))

print("FEW SHOT:")
print(accuracy_score(balanced_data["Style"], balanced_data["t5_few_shot"]))
print(precision_score(balanced_data["Style"], balanced_data["t5_few_shot"], pos_label="negative", zero_division=0))
print(recall_score(balanced_data["Style"], balanced_data["t5_few_shot"], pos_label="negative", zero_division=0))
print(f1_score(balanced_data["Style"], balanced_data["t5_few_shot"], pos_label="negative", zero_division=0))

"""BART zero-shot & few-shot prompting"""

from transformers import BartTokenizer, BartForConditionalGeneration

tokenizer_bart = BartTokenizer.from_pretrained("facebook/bart-base")

model_bart =  BartForConditionalGeneration.from_pretrained("facebook/bart-base")

def zero_shot_bart(sentence):
    prompt = f"Classify the sentiment as positive or negative:\n{sentence}"
    inputs = tokenizer_bart(prompt, return_tensors="pt")

    output_ids = model_bart.generate(**inputs, max_length=5)
    pred = tokenizer_bart.decode(output_ids[0], skip_special_tokens=True).lower()

    if "positive" in pred:
        return "positive"
    elif "negative" in pred:
        return "negative"
    else:
        return "negative"

def few_shot_bart(sentence):
    prompt = f"""
Review: I love this place.
Sentiment: positive

Review: The service was terrible.
Sentiment: negative

Now classify:
Review: {sentence}
Sentiment:
"""
    inputs = tokenizer_bart(prompt, return_tensors="pt")
    output_ids = model_bart.generate(**inputs, max_length=5)
    pred = tokenizer_bart.decode(output_ids[0], skip_special_tokens=True).lower()

    if "positive" in pred:
        return "positive"
    elif "negative" in pred:
        return "negative"
    else:
        return "negative"

data = pd.read_csv('train_en.txt', sep='\t')

positive_data = data[data['Style']== 'positive'].sample(n=500, random_state=42)
negative_data = data[data['Style'] == 'negative'].sample(n=500, random_state=42)

balanced_data = pd.concat([positive_data, negative_data], ignore_index=True)
balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)

balanced_data["bart_zero_shot"] = balanced_data["Sentence"].apply(zero_shot_bart)

balanced_data["bart_few_shot"] = balanced_data["Sentence"].apply(few_shot_bart)

print("ZERO SHOT positive label:")
print(accuracy_score(balanced_data["Style"], balanced_data["bart_zero_shot"]))
print(precision_score(balanced_data["Style"], balanced_data["bart_zero_shot"], pos_label="positive", zero_division=0))
print(recall_score(balanced_data["Style"], balanced_data["bart_zero_shot"], pos_label="positive", zero_division=0))
print(f1_score(balanced_data["Style"], balanced_data["bart_zero_shot"], pos_label="positive", zero_division=0))

print("ZERO SHOT negative label:")
print(accuracy_score(balanced_data["Style"], balanced_data["bart_zero_shot"]))
print(precision_score(balanced_data["Style"], balanced_data["bart_zero_shot"], pos_label="negative", zero_division=0))
print(recall_score(balanced_data["Style"], balanced_data["bart_zero_shot"], pos_label="negative", zero_division=0))
print(f1_score(balanced_data["Style"], balanced_data["bart_zero_shot"], pos_label="negative", zero_division=0))

print("FEW SHOT positive label:")
print(accuracy_score(balanced_data["Style"], balanced_data["bart_few_shot"]))
print(precision_score(balanced_data["Style"], balanced_data["bart_few_shot"], pos_label="positive", zero_division=0))
print(recall_score(balanced_data["Style"], balanced_data["bart_few_shot"], pos_label="positive", zero_division=0))
print(f1_score(balanced_data["Style"], balanced_data["bart_few_shot"], pos_label="positive", zero_division=0))

print("FEW SHOT negative label:")
print(accuracy_score(balanced_data["Style"], balanced_data["bart_few_shot"]))
print(precision_score(balanced_data["Style"], balanced_data["bart_few_shot"], pos_label="negative", zero_division=0))
print(recall_score(balanced_data["Style"], balanced_data["bart_few_shot"], pos_label="negative", zero_division=0))
print(f1_score(balanced_data["Style"], balanced_data["bart_few_shot"], pos_label="negative", zero_division=0))

"""За последниот пример зедов помал број на податоци поради предолготрајно извршување

* Промптинг техниките даваат многу послаби резултати од трансфер архитектурите, посебно zero-shot без дополнителен prompting не е соодветен за бинарна класификација.
"""

